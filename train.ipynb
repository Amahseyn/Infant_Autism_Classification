{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_and_preprocess_features(main_directory, size=64):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Traverse the main directory and subfolders\n",
    "    for subfolder in os.listdir(main_directory):\n",
    "        subfolder_path = os.path.join(main_directory, subfolder)\n",
    "\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Determine the label from the subfolder name (TD for normal, ASD for autism)\n",
    "            label = 0 if \"TD\" in subfolder else 1  # 0 for normal, 1 for autism\n",
    "            \n",
    "            # Loop through files in the subfolder\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                if file.endswith('_features.txt'):\n",
    "                    file_path = os.path.join(subfolder_path, file)\n",
    "                    \n",
    "                    # Read features from the .txt file\n",
    "                    feature_data = {}\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        current_feature = None\n",
    "                        for line in lines:\n",
    "                            if line.startswith(\"Feature:\"):\n",
    "                                current_feature = line.strip().split(\":\")[1].strip()\n",
    "                                feature_data[current_feature] = []\n",
    "                            elif current_feature:\n",
    "                                try:\n",
    "                                    # Ensure the line contains valid numbers\n",
    "                                    feature_values = list(map(float, line.strip().split(',')))\n",
    "                                    feature_data[current_feature].append(feature_values)\n",
    "                                except ValueError:\n",
    "                                    # Skip lines that do not contain valid numeric data\n",
    "                                    continue\n",
    "                    \n",
    "                    # Resize and concatenate features\n",
    "                    all_features = []\n",
    "                    for feature_name, feature_values in feature_data.items():\n",
    "                        feature_array = np.array(feature_values)\n",
    "                        resized_feature = resize(feature_array, (size, size))\n",
    "                        all_features.append(resized_feature)\n",
    "\n",
    "                    # Stack features into 3D (size, size, num_features)\n",
    "                    concatenated_features = np.stack(all_features, axis=-1)\n",
    "                    features.append(concatenated_features)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Directories for train, validation, and test sets\n",
    "main_directory = \"data/Clean_splited\"\n",
    "train_dir = os.path.join(main_directory, \"train\")\n",
    "val_dir = os.path.join(main_directory, \"val\")\n",
    "test_dir = os.path.join(main_directory, \"test\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_train, y_train = load_and_preprocess_features(train_dir, size=256)\n",
    "X_val, y_val = load_and_preprocess_features(val_dir, size=256)\n",
    "X_test, y_test = load_and_preprocess_features(test_dir, size=256)\n",
    "\n",
    "# Reshape and normalize the data\n",
    "X_train = X_train.astype('float32') / np.max(X_train)\n",
    "X_val = X_val.astype('float32') / np.max(X_val)\n",
    "X_test = X_test.astype('float32') / np.max(X_test)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_val = to_categorical(y_val, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, X_train.shape[-1])),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the CNN model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_test_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_test_true, y_test_pred, target_names=[\"Normal\", \"Autism\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvoice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
